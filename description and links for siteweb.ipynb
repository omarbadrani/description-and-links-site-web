{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5167e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ask the user for the URL they want to extract information from\n",
    "user_input_url = input(\"Enter the URL of the website you want to extract information from: \")\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the user-provided URL\n",
    "    response = requests.get(user_input_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract website information\n",
    "        title = soup.find('title').get_text() if soup.find('title') else \"Title not found\"\n",
    "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
    "        meta_description = meta_description['content'] if meta_description else \"Meta description not found\"\n",
    "\n",
    "        # Print the extracted information\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Meta Description: {meta_description}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred while making the request: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Ask the user for the URL they want to extract information from\n",
    "user_input_url = input(\"Enter the URL of the website you want to extract information from: \")\n",
    "\n",
    "try:\n",
    "    # Send an HTTP GET request to the user-provided URL\n",
    "    response = requests.get(user_input_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract website information\n",
    "        title = soup.find('title').get_text() if soup.find('title') else \"Title not found\"\n",
    "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
    "        meta_description = meta_description['content'] if meta_description else \"Meta description not found\"\n",
    "\n",
    "        # Extract headers (h1, h2, h3, etc.)\n",
    "        headers = [header.get_text() for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
    "\n",
    "        # Extract links\n",
    "        links = [link['href'] for link in soup.find_all('a', href=True)]\n",
    "\n",
    "        # Print the extracted information\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Meta Description: {meta_description}\")\n",
    "        print(\"Headers:\")\n",
    "        for header in headers:\n",
    "            print(header)\n",
    "        print(\"Links:\")\n",
    "        for link in links:\n",
    "            print(link)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred while making the request: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_user_input_url():\n",
    "    while True:\n",
    "        user_input_url = input(\"Enter the URL of the website you want to extract information from: \")\n",
    "        # Basic URL validation\n",
    "        if user_input_url.startswith(('http://', 'https://')):\n",
    "            return user_input_url\n",
    "        else:\n",
    "            print(\"Invalid URL. Please enter a valid URL.\")\n",
    "\n",
    "def extract_emails(text):\n",
    "    # Using a basic email regex pattern\n",
    "    email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "    return re.findall(email_pattern, text)\n",
    "\n",
    "try:\n",
    "    user_input_url = get_user_input_url()\n",
    "\n",
    "    # Send an HTTP GET request to the user-provided URL\n",
    "    response = requests.get(user_input_url)\n",
    "    response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract links\n",
    "        links = [link.get('href') for link in soup.find_all('a', href=True)]\n",
    "\n",
    "        # Extract email addresses from various elements on the page\n",
    "        email_addresses = extract_emails(response.text)\n",
    "\n",
    "        # Print the extracted information\n",
    "        print(\"\\nExtracted Information:\")\n",
    "        \n",
    "        print(\"\\nLinks:\")\n",
    "        print('\\n'.join(links) if links else \"No links found\")\n",
    "\n",
    "        print(\"\\nEmail Addresses:\")\n",
    "        print('\\n'.join(email_addresses) if email_addresses else \"No email addresses found\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred while making the request: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
